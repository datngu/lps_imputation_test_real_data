{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7729e556-6fdd-4377-bd95-f4a3fe089e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from utils.attention_toolkit import *\n",
    "\n",
    "## require torch version >= 2.1.0\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "\n",
    "## cusomized layer normalization\n",
    "class MyLayerNorm(nn.Module):\n",
    "    def __init__(self, features, dim = -2, eps=1e-5):\n",
    "        super(MyLayerNorm, self).__init__()\n",
    "        assert dim in [-2, -1], 'dim must be -1 or -2'\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = self.dim, keepdim=True)\n",
    "        std = x.std( dim= self.dim, keepdim=True)\n",
    "        x_normalized = (x - mean) / (std + self.eps)\n",
    "        if self.dim == -2:\n",
    "            res = self.gamma[:,None] * x_normalized + self.beta[:,None]\n",
    "        else:\n",
    "            res = self.gamma * x_normalized + self.beta\n",
    "        return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CNN_Block_mynorm(nn.Module):\n",
    "    def __init__(self, n_input, n_output, kernel_size=3, pool=2, activation = F.relu):\n",
    "        super().__init__()\n",
    "        self.skip = nn.Conv1d(n_input, n_output, kernel_size=1)\n",
    "        self.norm = MyLayerNorm(n_output)\n",
    "        self.c1 = nn.Conv1d(n_input, n_output, kernel_size=kernel_size, padding=kernel_size // 2,\n",
    "        bias=False)\n",
    "        self.c2 = nn.Conv1d(n_output, n_output, kernel_size=kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.c3 = nn.Conv1d(n_output, n_output, kernel_size=kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.max_pool = nn.MaxPool1d(kernel_size=pool, stride=pool)  \n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.activation = activation\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip = self.skip(x)\n",
    "        x = self.activation(self.c1(x))\n",
    "        x = self.activation(self.c2(x))\n",
    "        x = self.activation(self.c3(x))\n",
    "        x = self.norm(x + skip)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class RotaryEmbedding(nn.Module):\n",
    "    # modified from : https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py\n",
    "    def __init__(self, dim, max_position_embeddings=2048, base=10000, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.base = base\n",
    "        inv_freq = 1.0 / (self.base ** (torch.arange(0, self.dim, 2).float().to(device) / self.dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "\n",
    "        # Build here to make `torch.jit.trace` work.\n",
    "        self._set_cos_sin_cache(\n",
    "            seq_len=max_position_embeddings, device=self.inv_freq.device, dtype=torch.get_default_dtype()\n",
    "        )\n",
    "\n",
    "    def _set_cos_sin_cache(self, seq_len, device, dtype):\n",
    "        self.max_seq_len_cached = seq_len\n",
    "        t = torch.arange(self.max_seq_len_cached, device=device, dtype=self.inv_freq.dtype)\n",
    "\n",
    "        freqs = torch.outer(t, self.inv_freq.to(device))\n",
    "        # Different from paper, but it uses a different permutation in order to obtain the same calculation\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        self.register_buffer(\"cos_cached\", emb.cos().to(dtype), persistent=False)\n",
    "        self.register_buffer(\"sin_cached\", emb.sin().to(dtype), persistent=False)\n",
    "\n",
    "    def _rotate_half(self, x):\n",
    "        \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "        x1 = x[..., : x.shape[-1] // 2]\n",
    "        x2 = x[..., x.shape[-1] // 2 :]\n",
    "        return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "\n",
    "    def forward(self, q, k, seq_len_dim = -2):\n",
    "        \"\"\"Applies Rotary Position Embedding to the query and key tensors.\n",
    "        # modified from https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py\n",
    "        Args:\n",
    "            q (`torch.Tensor`): The query tensor. #[..., seq_len, head_dim]\n",
    "            k (`torch.Tensor`): The key tensor. # [..., seq_len, head_dim]\n",
    "            seq_len_dim : demension of sequence length that should be -2 given # [..., seq_len, head_dim]\n",
    "        Returns:\n",
    "            `tuple(torch.Tensor)` comprising of the query and key tensors rotated using the Rotary Position Embedding.\n",
    "        \"\"\"\n",
    "        seq_len = q.shape[seq_len_dim]\n",
    "        if q.device != self.cos_cached.device or seq_len > self.max_seq_len_cached:\n",
    "            self._set_cos_sin_cache(seq_len= max(seq_len, self.max_seq_len_cached)\n",
    "                                    , device=q.device, dtype=q.dtype)\n",
    "\n",
    "        cos = self.cos_cached[:seq_len]\n",
    "        sin = self.sin_cached[:seq_len]\n",
    "        # auto broadcasting\n",
    "        #cos = cos[None, None, : , :]\n",
    "        #sin = sin[None, None, :, :]\n",
    "        q_embed = (q * cos) + (self._rotate_half(q) * sin)\n",
    "        k_embed = (k * cos) + (self._rotate_half(k) * sin)\n",
    "        \n",
    "        return q_embed, k_embed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self, d_input, d_output, d_k, n_head, drop = 0.1, activation= F.relu, bias = False, keep_attention_score = False):\n",
    "        super().__init__()\n",
    "        d_model = d_k * n_head\n",
    "        self.WQ = nn.Linear(d_input, d_model, bias = bias)\n",
    "        self.WK = nn.Linear(d_input, d_model, bias = bias)\n",
    "        self.WV = nn.Linear(d_input, d_model, bias = bias)\n",
    "        self.WO = nn.Linear(d_model, d_output, bias = bias)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.RoEmb = RotaryEmbedding(d_k)\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_k\n",
    "        self.n_head = n_head\n",
    "        self.activation = activation\n",
    "        ## torch.nn.functional.scaled_dot_product_attention notation\n",
    "        self.scale = 1/torch.tensor(d_k ** 0.5)\n",
    "        self.keep_attention_score = keep_attention_score\n",
    "        self.keep_V = None\n",
    "        self.keep_O = None \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size, d_seq, _ = x.shape\n",
    "    \n",
    "        Q, K, V = self.WQ(x), self.WK(x), self.WV(x)\n",
    "        \n",
    "        if self.activation is not None:\n",
    "            Q = self.activation(Q)\n",
    "            K = self.activation(K)\n",
    "            V = self.activation(V)\n",
    "            \n",
    "\n",
    "        ## out Q, K, V shape is: (batch_size, n_head, d_seq, d_model)\n",
    "        Q = Q.reshape(batch_size, d_seq, self.n_head, -1).permute(0, 2, 1, 3)\n",
    "        K = K.reshape(batch_size, d_seq, self.n_head, -1).permute(0, 2, 1, 3)\n",
    "        V = V.reshape(batch_size, d_seq, self.n_head, -1).permute(0, 2, 1, 3)\n",
    "\n",
    "        # RoEmbeding\n",
    "        Q, K = self.RoEmb(Q, K)\n",
    "        \n",
    "        ## replaceed with flash attention implemented in PyTorch\n",
    "        ## the provided scaled_dot_product_attention is much more memory effient, and adaptive for hardware to speed up attention computation\n",
    "\n",
    "        #scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale\n",
    "        #attention = torch.softmax(scores, dim = -1)\n",
    "        #O = torch.matmul(attention, V)\n",
    "\n",
    "        O = torch.nn.functional.scaled_dot_product_attention(Q, K, V, scale = self.scale)\n",
    "\n",
    "        ## keep K and O for reconstruct attention score matrixes\n",
    "        if self.keep_attention_score:\n",
    "            self.keep_V = V.detach()\n",
    "            self.keep_O = O.detach()\n",
    "\n",
    "        # O shape (batch_size, n_head, d_seq, d_model), transpose to get back the right dimension before reshape        \n",
    "        O = O.transpose(1, 2).reshape(batch_size, d_seq, self.d_model)\n",
    "        O = self.WO(O)\n",
    "    \n",
    "        if self.activation is not None:\n",
    "            O = self.activation(O)\n",
    "        \n",
    "        O = self.drop(O)\n",
    "    \n",
    "        return O\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, ff_dim = 2048, d_embed_in = 128, d_embed_out = 64, d_k = 64, n_head = 12, drop = 0.1, keep_attention_score = False):\n",
    "        super().__init__()\n",
    "        self.atten = MHA(d_input = d_embed_in, d_output = d_embed_out, d_k = d_k, n_head = n_head, drop = drop, keep_attention_score = keep_attention_score)\n",
    "        self.drop1 = nn.Dropout(drop)\n",
    "        self.drop2 = nn.Dropout(drop)\n",
    "        self.norm1 = nn.LayerNorm(d_embed_out)\n",
    "        self.norm2 = nn.LayerNorm(d_embed_out)\n",
    "        self.ffn = nn.Sequential(\n",
    "          nn.Linear(d_embed_out, ff_dim),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(ff_dim,d_embed_out),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x1 = self.atten(input)\n",
    "        x1 = self.drop1(x1)\n",
    "        x1 = self.norm1(input + x1)\n",
    "        x = self.ffn(x1)\n",
    "        x = self.drop2(x)\n",
    "        x = self.norm2(x + x1)\n",
    "        return (x)\n",
    "\n",
    "\n",
    "MIN_FLOAT32 = torch.finfo(torch.float32).min\n",
    "MAX_FLOAT32 = torch.finfo(torch.float32).max\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_output, ff_dim = 2048, d_k = 64, n_head = 12, trans_drop = 0.1, keep_attention_score = False):\n",
    "        super().__init__()\n",
    "        kernel_size = 5\n",
    "        conv_layers = [32, 64, 128, 256]\n",
    "        conv_pools = [2,2,5,5]\n",
    "        L = []\n",
    "        c = 4\n",
    "        for (l, p) in zip(conv_layers, conv_pools):\n",
    "            L.append(CNN_Block_mynorm(c, l, kernel_size, p))\n",
    "            c = l\n",
    "        self.conv_tower = nn.Sequential(*L)\n",
    "        \n",
    "        self.trans1 = TransformerBlock(ff_dim=ff_dim, d_embed_in=conv_layers[-1], \\\n",
    "                                    d_embed_out=conv_layers[-1], d_k=d_k, n_head=n_head, drop=trans_drop, \\\n",
    "                                    keep_attention_score = keep_attention_score)\n",
    "\n",
    "        self.trans2 = TransformerBlock(ff_dim=ff_dim, d_embed_in=conv_layers[-1], \\\n",
    "                                    d_embed_out=conv_layers[-1], d_k=d_k, n_head=n_head, drop=trans_drop, \\\n",
    "                                    keep_attention_score = keep_attention_score)\n",
    "\n",
    "        self.trans3 = TransformerBlock(ff_dim=ff_dim, d_embed_in=conv_layers[-1], \\\n",
    "                                    d_embed_out=conv_layers[-1], d_k=d_k, n_head=n_head, drop=trans_drop, \\\n",
    "                                    keep_attention_score = keep_attention_score)\n",
    "\n",
    "        self.trans4 = TransformerBlock(ff_dim=ff_dim, d_embed_in=conv_layers[-1], \\\n",
    "                                    d_embed_out=conv_layers[-1], d_k=d_k, n_head=n_head, drop=trans_drop, \\\n",
    "                                    keep_attention_score = keep_attention_score)\n",
    "\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(10 * conv_layers[-1], 128),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Linear(128, n_output)\n",
    "\n",
    "    def forward(self, x, training=None, mask=None, **kwargs):\n",
    "        x = self.conv_tower(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.trans1(x)\n",
    "        x = self.trans2(x)\n",
    "        x = self.trans3(x)\n",
    "        x = self.trans4(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.classifier(x)\n",
    "        #x = torch.clamp(x, min = MIN_FLOAT32, max = MAX_FLOAT32)\n",
    "        return x\n",
    "\n",
    "\n",
    "## test code: \n",
    "## Model(95)(torch.rand(2,4,1000)).shape\n",
    "        # self.conv_pool_drop_1 = nn.Sequential(\n",
    "        #     nn.Conv1d(in_channels=4, out_channels=n_kernel, kernel_size=25, stride=1),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool1d(kernel_size=12, stride=12),\n",
    "        #     nn.Dropout(0.2),\n",
    "        #     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fe7f4c6-fcfb-45bf-ac52-d4a1b4e84df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 95])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model(95)(torch.rand(2,4,1000)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a4fbcfcb-ae22-4d77-9528-02775b0dcb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayerNorm(nn.Module):\n",
    "    def __init__(self, features, dim = -2, eps=1e-5):\n",
    "        super(MyLayerNorm, self).__init__()\n",
    "        assert dim in [-2, -1], 'dim must be -1 or -2'\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = self.dim, keepdim=True)\n",
    "        std = x.std( dim= self.dim, keepdim=True)\n",
    "        x_normalized = (x - mean) / (std + self.eps)\n",
    "        if self.dim == -2:\n",
    "            res = self.gamma[:,None] * x_normalized + self.beta[:,None]\n",
    "        else:\n",
    "            res = self.gamma * x_normalized + self.beta\n",
    "        return res\n",
    "\n",
    "\n",
    "class CNN_Block(nn.Module):\n",
    "    def __init__(self, n_input, n_output, kernel_size=25, pool=2, activation = F.gelu):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv1d(n_input, n_output, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.c2 = nn.Conv1d(n_output, n_output, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.norm1 = MyLayerNorm(n_output)\n",
    "        self.norm2 = MyLayerNorm(n_output)\n",
    "        self.max_pool = nn.MaxPool1d(kernel_size=pool, stride=pool)  \n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.activation = activation\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.c1(x))\n",
    "        x = self.norm1(x)\n",
    "        x = self.activation(self.c2(x))\n",
    "        x = self.norm2(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_output, ff_dim = 2048, d_k = 64, n_head = 12, trans_drop = 0.1, keep_attention_score = False):\n",
    "        super().__init__()\n",
    "        kernel_size = [25, 9, 9]\n",
    "        conv_layers = [64, 320, 640]\n",
    "        conv_pools = [5,5,1]\n",
    "        L = []\n",
    "        c = 4\n",
    "        for (l, p, k) in zip(conv_layers, conv_pools, kernel_size):\n",
    "            L.append(CNN_Block(c, l, k, p))\n",
    "            c = l\n",
    "        self.conv_tower = nn.Sequential(*L)\n",
    "        #self.norm_cnn = nn.LayerNorm(conv_layers[-1])\n",
    "        \n",
    "        self.trans1 = TransformerBlock(ff_dim=ff_dim, d_embed_in=conv_layers[-1], \\\n",
    "                                    d_embed_out=conv_layers[-1], d_k=d_k, n_head=n_head, drop=trans_drop, \\\n",
    "                                    keep_attention_score = keep_attention_score)\n",
    "\n",
    "\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(408 * conv_layers[-1], 128),\n",
    "            nn.GELU(),\n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Linear(128, n_output)\n",
    "\n",
    "    def forward(self, x, training=None, mask=None, **kwargs):\n",
    "        x = self.conv_tower(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        #x = self.norm_cnn(x)\n",
    "        x = self.trans1(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.classifier(x)\n",
    "        x = torch.clamp(x, min = MIN_FLOAT32, max = MAX_FLOAT32)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e2fd9d59-1eef-4ed5-9259-e260d35c9050",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Model(919)(torch.rand(2,4,10200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e25b4809-bbc9-4a35-b945-6a530f0ee4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44885271"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(Model(919))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f523d2dc-70f9-4788-99ad-cdd0ba794d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 919])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2fa05d-b056-422b-8261-880af6f25c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1808d5f-641d-4388-b280-729d1d360f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0dced741-bd69-4798-85a2-3b90d55d0330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195840"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*97920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45d82f98-a922-49e6-9841-75059936fac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-960"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "96960-97920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "166f73cc-0534-4a01-950c-4124e3e0953e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1931818181818181"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15/132* 10.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0ee7b747-228a-4c44-8904-0acc25dbcd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3* 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9fce8a29-cf47-4e86-af87-790af881131f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13157894736842105"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5/19 *5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c28d14eb-cd66-4570-b847-b055910653b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/15*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ff58941f-26ac-4b03-816e-48395615b6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1580940988835726"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3333333333333333 + 0.13157894736842105 + 1.1931818181818181 + 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "24e9b496-d6c2-404e-9e47-3bb1f6a02def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049606299212598425"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.15/63.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74b95a-1bd7-44c3-92fa-0d6e8dd9d68c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
